[{"title":"机器学习","date":"2019-07-26T14:12:52.000Z","path":"2019/07/26/机器学习/","text":"什么是机器学习 人脑学习的过程中，需要学习问题以及答案，得到解决这类问题的方法，面对新问题时，通过学习到的方法得出问题的答案。机器学习与人脑学习是一致的，输入训练集，训练出解决这类问题的模型，面对新问题时，通过训练出的模型预测出问题的答案。 机器学习概述数学基础 算法 架构 技术应用","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://anning1994.github.io/tags/机器学习/"}]},{"title":"补码","date":"2018-07-29T08:14:19.000Z","path":"2018/07/29/补码/","text":"基本概念 在计算机中，二进制数据有三种形式：原码、反码和补码，要弄清楚补码的意义，首先让我们来了解三种形式的定义。 假设字长为4，其中最高位为符号位：正数为0，负数为1。剩下的3位表示该数的绝对值。正数的原码反码补码都是一样的。 1.原码 +3的原码：0011 -3的原码：1011 2.反码 反码就是在原码的基础上，符号位不变其他位按位取反(就是0变1，1变0)就可以了。 +3的反码：0011 -3的反码：1100 3.补码 补码也非常的简单，就是在反码的基础上按照正常的加法运算加1。 +3的补码：0011 -3的补码：1101 从前面的三种数字编码类型的定义，我们可以看出数据的原码，使用符号位来区分了正负数，更加符合人脑直观识别并且用于计算的表达方式。但是在计算机中，是通过补码的形式保存数据，下面将解释为什么计算机系统要用补码存放数据。 周期系统 若一组事件或现象按同样的顺序重复出现，则把完成这一组事件或现象的时间或空间间隔，称为周期。 周期性原码累加系统定义一个字长为4的二进制累加系统，该系统的规则就是从左到右依次累加0001； 0000 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 1100 1101 1110 1111 0000 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 如果最高位是符号位时，图表第二行表示原码对应的10进制数，不难发现，如果在确定字长为4时，累加过程是符合周期性变化的，原因就是当1111+1时会出现字节溢出的情况，10000的最高位溢出失效，导致结果变为0000； 周期性时钟系统 在现实生活中，时钟显然是符合周期性的，12点过后是1点，人们早已习惯了这种思维方式，所以会忽略对时钟这种表示时间方式的思考。凌晨12点加1个小时，其实表式的时间是天数加1之后的1点，但是对于时钟系统而言，天数不是自己所能表示的，这就相当于上面图表中1111+1=0000(1|0000 1是溢出位，在字长为4的系统中是不能表示的)。 时钟系统和二进制数原码的累加系统都有周期性，具有周期性的原因是当前层次系统中有其不能表示或未能感知的其他层次系统。 计算机运算系统正是利用了周期性的这一特性。 周期系统中的加减转化时钟系统加减法转化假设时针向顺时针方向拨动为加，逆时针拨动为减。 7点顺时针拨动1格表示的是：7+1=8 7点逆时针拨动1格表示的是：7-1=6 7点顺时针拨动11格表示的是：7+11=6 所以很容易发现，在时钟中7-1=7+11，这就是周期系统中加减法发的转化方式，其实和简单，也很符合我们的直觉。 所以重新考虑原码的减法问题，n-m = n+(MAX-m),其中MAX就是该周期中所能表示的所有数的数量，放到上面原码的例子中就是16个，而放到时钟系统中就是12个。如： 周期性的时钟系统: 12 - 1 = 12 + （12 -1）； 7 - 4 = 7 +（12-4）； 累加系统加减法转化在说原码累加系统加减法转化例子之前，我们再看下图表 A 0000 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 1100 1101 1110 1111 0000 A1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 A2 0 1 2 3 4 5 6 7 -0 -1 -2 -3 -4 -5 -6 -7 0 B 0000 0001 0010 0011 0100 0101 0110 0111 1111 1110 1101 1100 1011 1010 1001 1000 0000 B1 0 1 2 3 4 5 6 7 -7 -6 -5 -4 -3 -2 -1 -0 0 B2 0 1 2 3 4 5 6 7 -8 -7 -6 -5 -4 -3 -2 -1 0 为了方便说明在每一行的开始定义了该行的名称分别为A、A1、A2、B、B1、B2. 累加系统不同于周期系统的一点是会有负数的概念出现，A2行就是最高位表示符号位时原码解码后表示的十进制数。在图表中发现，当有符号位时二进制原码的累加转换为十进制数时，出现了与我们现实生活数学公理相违背的现象，错误发生在最高位为1后，如1001+1=1010(-1+1=-2)，原因是在定义这个累加系统在运算时就没有让系统知道高位0与1有不同之处，也就是累加的计算过程中无法感知符号。 解决问题的方式有两种 去重新完善这个累加系统，让他在最高位为1换一套计算方式，也就是说在运算过程中去感知最高位的意义。 转化出现问题的状态，使状态转移为当前系统能使用的，也就是在编码过程中去让无法感知符号的运算系统计算出正确的结果。 在计算机系统中，解决这个问题的方式显然是用第二种，cpu是无法感知符号位的，这样做可以减少cpu设计难度，极大地提高运行效率。 所以也就是说cpu运算时还是按照A行进行累加，但在解码运算结果时做一些处理，即将A转变为B，而B1是不考虑溢出和临界值时的十进制正确结果。A解码为B的算法就是当最高位为1时，符号位不变，其他位取反，不难发现这就是反码的定义。 当这样转化后会发现出现了0和-0两个0并且会出现0 - 1 = -0这种情况(将0向左移动)。所以还得做一个简单的处理，就是去加一个1，也就是B1转化为B2,而B2就是最终的正确十进制值。 其实按照直觉可以发现，当符号位转化时，其他位应该取反才能得到正确结果，正数越加越大，负数越加越小。 根据我们的努力将A通过反码的解码方式转变为B,而让B的解码结果加1(补码)，得到了B2,从而使累加系统当出现负数时变得合理起来。在转变为B2之后，我们需要解决的是如何用累加系统去表示减法。本质上和前面的时钟系统转化是一样的。可以借助上面的时钟系统以及下面的例子去理解累加系统的减法运算。 在看例子之前，稍微介绍一下“模” 的概念:模是指一个计量系统的计数范围，取模运算实质上是计量器产生“溢出”的量，前面的周期系统中n-m = n+(MAX-m)得出的加减转化其实就是用到了模的概念，MAX就是模。 计算 4 - 3 编码 0100 - 0011 //n-m = n+(MAX-m) ==》(10000-0011) 其结果就是0011的补码 转化为 0100 + (10000-0011) = 0100 + 1101 cpu调用加法器得出 10001 最高位溢出 0001 解码 1 重新计算 3 - 4 编码 0011 - 0100 转化为 0011 + (10000-0100) = 0011 + 1100 cpu调用加法器得出 1111 //参考A转变B2(也就是原码转补码) 解码-0001= -1 总结在计算机系统中，计算整数加减法时，需要经过以下步骤： 转变为2进制数； 运算时原码解码为补码；n-m = n+(MAX-m)，(MAX-m)也就是m的补码，理解时参考时钟系统。 cpu调用加法器； 解码；再进行一次补码解码，理解时参考A转化为B2。","tags":[{"name":"计算机原理","slug":"计算机原理","permalink":"http://anning1994.github.io/tags/计算机原理/"}]},{"title":"Java并发编程","date":"2018-04-06T14:12:52.000Z","path":"2018/04/06/Java并发编程详解/","text":"Java并发编程的底层实现原理主要是对voaltile以及synchronized的JVM层实现进行说明。 voaltile如果一个字段被声明为voaltile,Java内存模型确保所有线程看到这个变量的值是一致的。其原理是，当声明voaltilede变量在编译后会生成lock前缀指令。 会使处理器缓存行的数据写回到内存中（刷新变量）。 写回内存中的值在其他cpu缓存中失效。 synchronizeJava中每一个对象都可以作为锁。 普通方法：锁是该对象的实例。静态方法：锁是当前类的Class对象。同步方法块：锁是synchronize的配置对象 当一个线程试图访问同步代码时必须获取锁，退出或者抛出异常时必须释放锁。 Java SE 1.6后为了减少获取和释放锁带来的性能消耗，引入偏向锁和轻量级锁。 1.偏向锁 大部分时间不存在线程竞争，且总是由一个线程多次获取锁，为了这种情况代价更低，引入了偏向锁。当一个线程已经获取锁时，会在对象头中的锁记录中存储偏向的线程Id,当线程再次获取该对象的锁时，不需要做任何复杂操作，只需要验证对象头中的偏向线程Id是否为当前线程即可。 当偏向锁撤销时，即有竞争出现偏向锁才释放锁，当释放偏向锁 2.轻量级锁 首先线程将自己栈帧中创建存储对象头的内存空间，之后复制对象头到线程的栈帧中，然后尝试使用CAS方式将对象头替换为指向锁记录的指针，如果成功，当前线程获取锁成功，如果失败表示存在竞争，则通过自旋来再次进行CAS替换。 当轻量级锁释放时，则是通过CAS换回到对象头，如果成功则表示没有竞争出现，如果失败表示有竞争。通过自旋方式释放。 自旋操作会一直消耗CPU,当一直自旋获取失败时会将锁升级为重量级锁。 3.重量级锁 重量级锁就是通过阻塞线程，需要切换线程上下文的一种方式。 JMMJMM是语音级的内存模型，是建立在处理器平台上的，为开发者屏蔽一些细节，如通过禁止特定类型的重排序。为开发者提供一致性的内存和可见性的保证。 happers-beforeJMM能保证程序按照happens-before规则执行。happens-before规则为 1.程序顺序规则 一个线程中的每个操作，happens-before于该线程之后的操作。 2.监视器锁规则 对一个锁的解锁，happens-before于随后对这个锁的加锁。 3.volatile变量规程 对一个volatile变量的写，happens-before于任意后续对于这个变量的读。 4.传递性 A happens-before于 B, B happens-before C,那么A happens-before于 C。 两个操作之间具有happens-before关系，不是指前一个操作必须在后一个操作之前执行，而是只前一个操作对后一个可见 对于Java程序员而言，happens-before规则简单易懂，它避免了Java程序员为理解JMM提供的内存可见性保证而且学习复杂的重排序规则以及规则的具体实现方法。 线程线程的状态 1.new 线程的初始状态，线程被创建，但是还没有start()。 2.runnable 运行状态，线程在操作系统中的就绪和运行两种状态统称为运行中。 3.blocked 阻塞状态，线程阻塞于锁 4.waiting 等待状态，需要等其他线程的操作而做一系列动作如（唤醒，中断） 4.time_waiting 超时等待状态，时间到了自动唤醒。 Java实现的锁Lock接口","tags":[{"name":"java","slug":"java","permalink":"http://anning1994.github.io/tags/java/"},{"name":"基础知识","slug":"基础知识","permalink":"http://anning1994.github.io/tags/基础知识/"}]},{"title":"如何正确的理解CAP(转载)","date":"2018-03-25T13:12:44.000Z","path":"2018/03/25/如何正确的理解CAP/","text":"原文链接： https://www.jdon.com/bigdata/how-to-understand-cap.html 在大数据领域，被业界广泛谈及的CAP理论存在着一些关键性的认知误区，而只有全面地考察与分析分布式环境中的各种场景，我们才能真正正确地理解它。目前，CAP（Consistency一致性、Availability可用性、Partition-tolerance分区可容忍性）理论普遍被当作是大数据技术的理论基础。同时，根据该理论，业界有一种非常流行、非常“专业”的认识，那就是：关系型数据库设计选择了C（一致性）与A（可用性），NoSQL数据库设计则不同。其中，HBase选择了C（一致性）与P（分区可容忍性），Cassandra选择了A（可用性）与P（分区可容忍性）。 该说法现在似乎已经成为一种经典认知，无论是初学大数据技术，还是已经有了相当经验的技术人员，都将其奉为真理。大家大概是认为，从CAP这样著名的理论推导出来的结论，当然是权威而又正确的，最起码在形式上感觉是专业而又严肃的。有人甚至还将这种认知画成一个三角形图，三个顶点分别是C、A、P，三条边分别是关系型数据库、HBase与Cassandra，这样一来，CAP理论就显然更加神圣了。 实际上，这种认识是不准确的，甚至是不正确的。暂且不说深入的分析与研究，只要先从表面上简单分析一下，你就能发现问题：难道说从理论上讲Cassandra就一定比HBase的可用性更高吗？而要要彻底搞清楚这个问题，还得先从CAP理论本身开始研究。 常见的理解及分析目前流行的、对CAP理论解释的情形是从同一数据在网络环境中的多个副本出发的。为了保证数据不会丢失，在企业级的数据管理方案中，一般必须考虑数据的冗余存储问题，而这应该是通过在网络上的其他独立物理存储节点上保留另一份、或多份数据副本来实现的（如附图所示）。因为在同一个存储节点上的数据冗余明显不能解决单点故障问题，这与通过多节点集群来提供更好的计算可用性的道理是相同的。 其实，不用做严格的证明也可以想见，如附图的情况，数据在节点A、B、C上保留了三份，如果对节点A上的数据进行了修改，然后再让客户端通过网络对该数据进行读取。那么，客户端的读取操作什么时候返回呢？ 有这样两种情况：一种情况是要求节点A、B、C的三份数据完全一致后返回。也就是说，这时从任何一个网络节点读取的数据都是一样的，这就是所谓的强一致性读。很明显，这时数据读取的Latency要高一些（因为要等数据在网络中的复制），同时A、B、C三个节点中任何一个宕机，都会导致数据不可用。也就是说，要保证强一致性，网络中的副本越多，数据的可用性就越差； 另一种情况是，允许读操作立即返回，容忍B节点的读取与A节点的读取不一致的情况发生。这样一来，可用性显然得到了提高，网络中的副本也可以多一些，唯一得不到保证的是数据一致性。当然，对写操作同样也有多个节点一致性的情况，在此不再赘述。 可以看出，上述对CAP理论的解释主要是从网络上多个节点之间的读写一致性出发考虑问题的。而这一点，对于关系型数据库意味着什么呢？当然主要是指通常所说的Standby（关于分布式事务，涉及到更多考虑，随后讨论）情况。对此，在实践中我们大多已经采取了弱一致性的异步延时同步方案，以提高可用性。这种情况并不存在关系型数据库为保证C、A而放弃P的情况；而对海量数据管理的需求，关系型数据库扩展过程中所遇到的性能瓶颈，似乎也并不是CAP理论中所描述的那种原因造成的。那么，上述流行的说法中所描述的关系型数据库为保证C、A而牺牲P到底是在指什么呢？ 因此，如果根据现有的大多数资料对CAP理论的如上解释，即只将其当作分布式系统中多个数据副本之间的读写一致性问题的通用理论对待，那么就可以得出结论：CAP既适用于NoSQL数据库，也适用于关系型数据库。它是NoSQL数据库、关系型数据库，乃至一切分布式系统在设计数据多个副本之间读写一致性问题时需要遵循的共同原则。 更深入的探究：两种重要的分布式场景在本文中我们要说的重点与核心是：关于对CAP理论中一致性C的理解，除了上述数据副本之间的读写一致性以外，分布式环境中还有两种非常重要的场景，如果不对它们进行认识与讨论，就永远无法全面地理解CAP，当然也就无法根据CAP做出正确的解释。但可惜的是，目前为止却很少有人提及这两种场景：那就是事务与关联。 先来看看分布式环境中的事务场景。我们知道，在关系型数据库的事务操作遵循ACID原则，其中的一致性C，主要是指一个事务中相关联的数据在事务操作结束后是一致的。所谓ACID原则，是指在写入/异动资料的过程中，为保证交易正确可靠所必须具备的四个特性：即原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）和持久性（Durability）。 例如银行的一个存款交易事务，将导致交易流水表增加一条记录。同时，必须导致账户表余额发生变化，这两个操作必须是一个事务中全部完成，保证相关数据的一致性。而前文解释的CAP理论中的C是指对一个数据多个备份的读写一致性。表面上看，这两者不是一回事，但实际上，却是本质基本相同的事物：数据请求会等待多个相关数据操作全部完成才返回。对分布式系统来讲，这就是我们通常所说的分布式事务问题。 众所周知，分布式事务一般采用两阶段提交策略来实现，这是一个非常耗时的复杂过程，会严重影响系统效率，在实践中我们尽量避免使用它。在实践过程中，如果我们为了扩展数据容量将数据分布式存储，而事务的要求又完全不能降低。那么，系统的可用性一定会大大降低，在现实中我们一般都采用对这些数据不分散存储的策略。 当然，我们也可以说，最常使用的关系型数据库，因为这个原因，扩展性（分区可容忍性P）受到了限制，这是完全符合CAP理论的。但同时我们应该意识到，这对NoSQL数据库也是一样的。如果NoSQL数据库也要求严格的分布式事务功能，情况并不会比关系型数据库好多少。只是在NoSQL的设计中，我们往往会弱化甚至去除事务的功能，该问题才表现得不那么明显而已。 因此，在扩展性问题上，如果要说关系型数据库是为了保证C、A而牺牲P，在尽量避免分布式事务这一点上来看，应该是正确的。也就是说：关系型数据库应该具有强大的事务功能，如果分区扩展，可用性就会降低；而NoSQL数据库干脆弱化甚至去除了事务功能，因此，分区的可扩展性就大大增加了。 再来看看分布式环境中的关联场景。初看起来，关系型数据库中常用的多表关联操作与CAP理论就更加不沾边了。但仔细考虑，也可以用它来解释数据库分区扩展对关联所带来的影响。对一个数据库来讲，采用了分区扩展策略来扩充容量，数据分散存储了，很显然多表关联的性能就会下降，因为我们必须在网络上进行大量的数据迁移操作，这与CAP理论中数据副本之间的同步操作本质上也是相同的。 因此，如果要保证系统的高可用性，需要同时实现强大的多表关系操作的关系型数据库在分区可扩展性上就遇到了极大的限制（即使是那些采用了各种优秀解决方案的MPP架构的关系型数据库，如TeraData，Netezza等，其水平可扩展性也是远远不如NoSQL数据库的），而NoSQL数据库则干脆在设计上弱化甚至去除了多表关联操作。那么，从这一点上来理解“NoSQL数据库是为了保证A与P，而牺牲C”的说法，也是可以讲得通的。当然，我们应该理解，关联问题在很多情况下不是并行处理的优点所在，这在很大程度上与Amdahl定律相符合。 所以，从事务与关联的角度来关系型数据库的分区可扩展性为什么受限的原因是最为清楚的。而NoSQL数据库也正是因为弱化，甚至去除了像事务与关联（全面地讲，其实还有索引等特性）等在分布式环境中会严重影响系统可用性的功能，才获得了更好的水平可扩展性。 那么，如果将事务与关联也纳入CAP理论中一致性C的范畴的话，问题就很清楚了：关于“关系型数据库为了保证一致性C与可用性A，而不得不牺牲分区可容忍性P”的说法便是正确的了。但关于“NoSQL选择了C与P，或者A与P”的说法则是错误的，所有的NoSQL数据库在设计策略的大方向上都是选择了A与P（虽然对同一数据多个副本的读写一致性问题的设计各有不同），从来没有完全选择C与P的情况存在。 结论现在看来，如果理解CAP理论只是指多个数据副本之间读写一致性的问题，那么它对关系型数据库与NoSQL数据库来讲是完全一样的，它只是运行在分布式环境中的数据管理设施在设计读写一致性问题时需要遵循的一个原则而已，却并不是NoSQL数据库具有优秀的水平可扩展性的真正原因。而如果将CAP理论中的一致性C理解为读写一致性、事务与关联操作的综合，则可以认为关系型数据库选择了C与A，而NoSQL数据库则全都是选择了A与P，但并没有选择C与P的情况存在。这才是用CAP理论来支持NoSQL数据库设计正确认识。 其实，这种认识正好与被广泛认同的NoSQL的另一个理论基础相吻合，即与ACID对着干的BASE（基本可用性、软状态与最终一致性）。因为BASE的含义正好是指“NoSQL数据库设计可以通过牺牲一定的数据一致性和容错性来换取高性能的保持甚至提高”，即NoSQL数据库都应该是牺牲C来换取P，而不是牺牲A。可用性A正好是所有NoSQL数据库都普遍追求的特性。","tags":[{"name":"宏观知识","slug":"宏观知识","permalink":"http://anning1994.github.io/tags/宏观知识/"}]},{"title":"深入分析Java虚拟机","date":"2018-01-25T12:12:44.000Z","path":"2018/01/25/深入解析Java虚拟机/","text":"Java虚拟机是相对于物理机的概念，也就是对现有冯诺依曼体系结构的硬件系统的抽象，现有计算机硬件系统是由输入，运算器、控制器、存储器和输出构成的。Java虚拟机则是建立在硬件系统之上，提供自己的规范，使在虚拟机上运行的程序具有跨平台、自动回收内存等诸多特性。 虚拟机内存划分概述Java虚拟机对内存划分为5种不同的区域，分别是栈内存、本地方法栈、堆内存、方法区、程序计数器。 栈内存栈内存是线程私有的，它随着线程的创建而创建，随着线程的销毁而销毁，在执行方法时会创建栈帧，栈帧中存放的是局部变量表（方法的参数以及局部变量）、操作数栈（指令所操作的数据存放处）等信息。方法的调用就是栈帧入栈的过程。 本地方法栈执行Native方法时所用到的存储单元 堆内存堆内存是线程共享的，当虚拟机启动时便会创建。该内存区域是用来存放对象实例的，也是垃圾收集器管理的主要区域。 方法区方法区是线程共享的内存区域，它存储的主要是在类加载时产生的数据，可以理解为是存储Class文件信息或者是类相关信息的。所以编译后的字节码、常量、静态变量等与对象无关只有类有关的数据都放在这里。 程序计数器程序计数器作为线程执行时的行号指示器，分支、跳转、循环都是通过它实现的，在任一时刻，一个处理器核都只会执行一条线程中的指令，每一个核对应一个程序计数器。 Class文件详解Java原码中的各种变量，关键字和运算符号的语义最终都是由多条字节码命令组合而成的，而ava原码通过编译器编译为虚拟机可加载的Class文件，Class文件中包含了Java字节码和符号表和其他辅助信息。 Class文件是一组以8位字节为原子单位的二进制流，各个数据严格按照规定的顺序紧凑的排列（顺序中包含着信息），而Class文件只包含两种数据类型： 无符号数 – 表示数字、索引引用、数量值、或按照UTF-8表示字符串，通过u1、u2、u4表示1字节2字节4字节 表 – 是由多个无符号数组成的复合结构，所有表都以”_info”结尾 类型 名称 描述 数量 u4 magic 魔数 1 u2 minor_version 副版本号 1 u2 major 主版本号 1 u2 constant_pool_count 常量池数量 1 cp_info constant_pool 常量池 常量池数量-1 u2 access_flags 访问标识 1 u2 this_class 类索引 2 u2 super_class 父类索引 2 u2 interfaces_count 接口数量 1 u2 interfaces 接口索引集合 接口数量 u2 fields_count 字段数量 1 field_info fields 字段表 字段数量 u2 methods_counts 方法数量 1 method_info methods 方法表 方法数量 u2 attributes_count 属性数量 1 attributes_info attributes 属性表 属性数量 魔数以及版本号Class文件的前4个字节是魔数它的唯一作用就是确定这个文件是Class文件，接下来2个字节是副版本号，再接下来两个字节是主版本号，用来确定版本号。 常量池数量由于每个Class文件的常量数量不是固定的，所以紧接着主版本号后面的是常量池数量，用来确定常量的数量 常量池根据常量池的数量，后面是常量的具体内容，常量池中包含两大类常量： 字面量：字面量就是没有特殊意义的常量，就是用来表示常量，比如文本字符串（字段名等），或是被final修饰的常量值等 符号引用包括以下三类 类和接口的全限定名（用来确定类和接口） 字段名称和描述符（用来确定字段及字段的其他信息） 方法名称和描述符（用来确定字段及字段的其他信息） 类型 标识 描述 CONSTONT_utf8_info 1 utf8编码字符串 CONSTONT_Integer_info 3 整型字面量 CONSTONT_Float_info 4 浮点型字面量 CONSTONT_Long_info 5 长整型字面量 CONSTONT_Double_info 6 双精度浮点型字面量 CONSTONT_Class_info 7 类或者接口的符号引用 CONSTONT_String_info 8 字符串类型字面量 CONSTONT_Fieldref_info 9 字段的符号引用 CONSTONT_Methodref_info 10 方法的符号应用 CONSTONT_InterfaceMethodref_info 11 接口方法的符号应用 CONSTONT_NameAndType_info 12 字段或方法的部分引用 CONSTONT_MethodHandle_info 15 方法的句柄 CONSTONT_MethodType_info 16 方法的类型 CONSTONT_InvokeDynamic_info 18 动态方法调用点 常量池中的数据是以_info结尾，前面讲到Class文件只有两种类型，无符号数和表，而常量池的数据全部都是表，也就是由多个无符号数组成的复合结构。 常量池是提供其他表进行引用的，一个class文件中的所有出现的字符都该在常量池中显示 访问标识在常量池结束之后，接着的是2个字节的访问标识，用于识别该文件是类还是接口、是否为public、是否为abstract等信息 类索引、父类索引、接口索引集合在访问标识后的为类索引，是这个类的的全限定名，指向常量池中的CONSTONT_Class_info 字段表和方法表字段表用于表述接口或者类中声明的变量。 类型 名称 描述 u2 access_flags 描述字段、方法作用域等信息 u2 name_index 字段、方法简单名称常 u2 descriptor_index 字段、方法描述符 u2 attributes_count 属性数量 attributes_info attributes 属性表 属性表属性表的作用是对其他表额外进行描述，下面是一些常用的属性。 名称 使用位置 描述 code 方法表 编译后的字节码指令 Exceptions 方法表 方法抛出的异常 其中code属性非常重要，如果把Java程序中的信息分为代码和元数据两部分，那么Code属性就是用来描述代码的，其他所有数据项都是用来描述元数据。 虚拟机类加载过程虚拟机类加载过程就是将原来磁盘中的代码加载到内存中。 类加载过程生命周期类加载的生命周期包括：加载、验证、准备、解析、初始化、使用、卸载。 其中加载、验证、准备、初始化、卸载这五个过程顺序是确定的，而解析阶段有可能在初始化前也有可能在初始化后，在初始化前的解析是静态绑定（前期绑定），也就是可以在编译时确定，而初始化后的解析是动态绑定（后期绑定）。 加载 通过类的全限定名来获取类的二进制流 将类加载到方法区中 生成这个类的Class对象，获取方法区数据的入口（反射时会使用的） 验证验证合法性 准备分配类变量内存，并且赋初值 解析将运行时常量池（类文件中的常量池加载到方法区）的符号引用替换为直接引用（内存地址）。 初始化执行方法，为准备阶段类变量的初值赋值。方法是编译器自动生成的，相当于为静态字段赋值的方法，并且会合并static{}代码块的代码。（加载阶段还为涉及到具体对象） 类加载器上面的生命周期是由类加载器完成的，对于任何一个类，都需要通过类加载器和这个类来确定在JVM中的唯一性。（同一个类不同类加载器加载后的Class对象的equals（）方法返回false） 双亲委派机制如果有一个类加载器收到加载请求，它首先会请求父加载器去加载，所以会导致所有加载请求都会到顶层的启动类加载器去；当父加载器无法完成加载请求（搜索范围没有这个类），就传递给子加载器加载。 字节码执行过程字节码源代码进过编译又经过类加载器加载到方法区中的，字节码的执行代表着程序运行时一个方法的执行。 运行时栈帧栈帧是方法执行时的数据结构，主要包括：局部变量表、操作数栈、动态连接、方法返回地址等。 局部变量表用来存放方法参数和方法的变量的存储空间。它的大小在编译期间就已经确定，存放到Code属性中。 操作数栈当方法开始执行时，操作数栈是空的，方法执行过程根据字节码会往操作数栈中写入和提取内容。 动态连接每个栈帧都包含一个指向运行时常量池中所属方法的引用，这个引用是为了完成方法调用过程中的动态连接（确定方法），其中静态方法和私有方法是编译器可知，运行期不可变的。所以在编译期就可以确定。如重载就是需要动态连接来确认的 方法返回地址就是方法的返回地址。。。。。 垃圾回收机制垃圾回收是回收堆内存中不使用的对象。 判断对象是否存活 引用计数算法每当有一个地方引用对象就将计数加1，当引用失效就减1，当计数器为零就说明对象不再被使用了。（无法解决对象循环引用） 可达性算法通过一系列GC Root 对象作为起点，当一个对象到GC Root 没有任何引用链相连就证明对象不可使用 垃圾收集算法 标记清除算法标记需要回收的对象，之后统一回收。（会产生内存碎片） 复制算法将内存二等分，每次使用一半，当一半内存使用完之后触发复制算法，将存活的对象复制到另外一半中。（内存缩小到原来的一半）。适用于新生代，大量对象死去，少量存活，移动很少的对象。 标记整理标记需要回收的对象，将所有存活对象移动到一端，清除边界意外的内存。","tags":[{"name":"java","slug":"java","permalink":"http://anning1994.github.io/tags/java/"},{"name":"基础知识","slug":"基础知识","permalink":"http://anning1994.github.io/tags/基础知识/"}]},{"title":"2017我的书单","date":"2018-01-07T02:12:44.000Z","path":"2018/01/07/2017我的书单/","text":"计算机相关1.深入理解Java虚拟机（★★★★★） 笔者认为编程也遵守巴莱多定律(28定律)，利用20%所学的东西就能解决你在工作中遇到的80%的问题，所以笔者推荐阅读本书，去掌握解决另外20%问题的技能。在网络上但凡涉及到虚拟机、java虚拟机内存划分、jvm内存模型、class文件加载、class文件解析、垃圾回收等博文，有80%都引用本书。所以笔者才找到此书，并在阅读过程中收获颇丰，系统性的认识了java虚拟机的相关知识。 2.Java编程思想（★★★☆☆） 笔者对该书籍的定位就是宏观、全面、权威的Java基础知识索引。书如其名，思想即为道，而语法则为术，道为正，术为正，则事半功倍。阅读此书也应该本着悟道而非学术为原则，宏观的去了解java的知识。非常不推荐利用该书去学习java基础，应当在对java有一定了解，并对面向对象编程思想有一定认知之后再来读它。读书获取知识的过程就是一种思想碰撞过程，你首先对书中所讲的内容有自己浅薄的一层认识，而在读的过程中来否定或者肯定你的认知，并要分析你的认知与作者的认知存在不同的原因是那些认知不同造成的？从而会产生出新的浅薄的认知，之后不断的在阅读中重复着这种过程，此为学习思想。 3.深入分析Java Web技术内幕（★★★☆☆） 这本书非常全面的介绍了的Java Web技术栈，非常适合去了解整个Java Web技术体系。这本书的定位就是尽可能的广泛去介绍知识，从而导致细节方面略有缺失，但也绝不是泛泛而谈。建议读者将此书定义为一个知识体系的索引，将此书快速阅读，从而了解自己的知识漏洞。 第1章 深入Web请求过程 第2章 深入分析Java I/O的工作机制 第3章 深入分析Java Web中的中文编码问题 第4章 Javac编译原理 第5章 深入class文件结构 第6章 深入分析ClassLoader 工作机制 第7章 JVM体系结构与工作方式 第8章 JVM内存管理 第9章 Servlet工作原理解析 第10章 深入理解Session与Cookie 第11章 Tomcat的系统架构与 设计模式 第12章 Jetty的工作原理解析 第13章 Spring框架的设计理念与 设计模式分析 第14章 Spring MVC工作机制与 设计模式 第15章 深入分析Ibatis框架之系统 架构与映射原理 第16章 Velocity工作原理解析 第17章 Velocity优化实践 4.深入剖析Tomcat（★★★☆☆） 这本书笔者只是粗略的去看完的，原因并不是说这个Tomcat原理不是很重要，恰恰相反笔者认为了解Servlet规范及Servlet容器是十分有必要的，这是Java Web的基础，也是与我们日常生产息息相关的东西。我们可以回头想想自己使用过很多年的Tomcat,真的了解它吗？知道它启动时要做什么工作吗？知道我们写的程序是怎么被Tomcat运行起来的吗？又知道web.xml，过滤器，监听器的原理是什么吗？知道Tomcat相关配置如何使用吗?这些问题是基础且重要的。如果不了解那就去读这本书，一定会让你收获满满。当你了解完这些，会对你日常的生产有新的认识。至于上面笔者说粗略阅读是因为觉得这本书讲的太深了，如果仔细阅读完的话产出投入比太低了，只要能读到了解了自己对Servlet容器的疑惑即可，剩下的细节留个印象，当你在生产过程中碰到有关问题再返回头去啃。当有明显的阅读目的时，吸收的效率会高很多。 5.大型网站技术架构核心原理与案例分析（★★★☆☆） 开卷有益，让读者了解一个典型的网站迭代过程，从中逐渐引出网站从小到大的发展过程中所面临的问题，最后有给出解决问题的多种方案，并分析了每种方案的优缺点，最后通过几个真实案例将前面的知识点做了一个总结。书中围绕着大型网站的性能、可用性、伸缩性、扩展性、安全性几点展开详细介绍。 其他6.乌合之众（★★☆☆☆） 名气很大的一本书，读完后收获一般，大多数结论都是断言，缺乏明确的推理，书中少有的例子也因为笔者对欧洲历史知识的匮乏而无法产生认同感，读到一半时，目的也由最初的获取知识转变为欣赏作者强烈的主观批判心理。可以看出作者的思想与成书年代的“乌合之众”格格不入，所以才使书中的观点极其主观，带有偏见，但作为一本流传百年的社会学书籍，亮点也是有的，并且很多观点至今都很适用。最后分享一句书中读到的一句很喜欢的话—“远见往往会让人走向怀疑和无为” 7.异类（★★★☆☆） 这本书与笔者产生了深刻的共鸣，全书都在分析“异类”优异于常人的原因，书中最大的优点就是坐着并不是通过列举优异之人需要怎样的品质，而是从国家、出生日期、机遇、家庭背景、时代背景、种族天赋等多个方面，经过大量的实验数据的验证，全面剖析那些优异于常人的人。使笔者可以站在自己的位置经过自己对自己条件的分析，去得出自己走向优异的条件组合。 8.论中国（★★★☆☆） 这本书的作者是美国前国务卿基辛格所写，要想了解中国仅仅只通过我们自己的视角是不够的，要用世界眼光去重新了解下中国的历史，现在与未来。读完此书能够了解客观的了解中国的近代史，能够了解中国与美国和苏联的精彩博弈，能够了解到政治战略上地缘政策到意识形态的相互转化，能够了解中华文化的博大精深。笔者能力有限，感觉有很多感想却有讲不出，但是真的很推荐读者去阅读此书，下面是笔者觉得值得分享的内容： 中华文明的一个特点是，它似乎没有起点。中华文明不是作为一个传统意义上的民族国家，而是作为一种永恒的自然现象在历史上出现。在历史意识中，中国是一个只需要复原而无需创建的既有国家。 9.这本书能让你戒烟（★★★★☆） 能让你戒烟。。。。 10.别逗了,费曼先生（★★★★★） 在介绍这本书之前先介绍一下费曼技巧： 第一步 选择一个你想要理解的概念选择一个你想要理解的概念，然后拿出一张白纸， 把这个概念写在白纸的最上边。 第二步 设想一种场景，你正要向别人传授这个概念在白纸上写下你对这个概念的解释， 就好像你正在教导一位新接触这个概念的学生一样。当你这样做的时候，你会更清楚地意识到关于这个概念你理解了多少， 以及是否还存在理解不清的地方。 第三步 如果你感觉卡壳了，就回顾一下学习资料无论何时你感觉卡壳了，都要回到原始的学习资料并重新学习让你感到卡壳的那部分，直到你领会得足够顺畅，顺畅到可以在纸上解释这个部分为止。 第四步 - 为了让你的讲解通俗易懂，简化语言表达最终的目的，是用你自己的语言，而不是学习资料中的语言来解释概念。如果你的解释很冗长或者令人迷惑，那就说明你对概念的理解可能并没有你自己想象得那么顺畅，你要努力简化语言表达，或者与已有的知识建立一种类比关系，以便更好地理解它。 一千个读者一千个哈姆雷特，这本书笔者不想做任何总结性的评论去影响你们自己的理解。强烈推荐大家阅读。下面是精彩的文章内容: “他们不是通过理解事情来学习，他们凭别的什么方式来学习–凭生搬硬套，或者别的什么名堂。他们的知识如此脆弱不堪！” “他们看来，教育和科学研究本身是苦差事，其价值在于它可能带来的实际利益，（这种卑锁的市侩之气！）” “一个伙伴对我说：“嘿，看那只鸟。那是什么鸟？” 我说：“我对这种鸟一无所知。”他说：“这是褐喉画眉”，又说，“你爸爸什么也没有告诉你。”但事实恰恰相反，我父亲当然教过我。看着一只鸟，父亲说：“知道这是什么鸟吗？这是褐喉画眉；但是在葡萄牙，它的名字是……在意大利，名字是……”，他说，“在中国，名字是……在日本，名字是……”等等。“喏，”他说，“各种语言中你都想知道它的名字叫什么，但是当你知道了所有这些名字之后，你其实对这鸟还是一无所知。你所知道的，仅仅是不同地方的人怎么称呼这种鸟而已。现在，”他说：“我们来‘看’这只鸟。”","tags":[{"name":"资源分享","slug":"资源分享","permalink":"http://anning1994.github.io/tags/资源分享/"}]},{"title":"otter浅析","date":"2017-10-30T12:51:08.000Z","path":"2017/10/30/otter/","text":"otter girthub链接： https://github.com/alibaba/otter 整体架构 子模块解释 zooKeeper 分布式一致性协调服务，主要用来调度配置好的node模块。 manager 管理中心，用来配置同步信息，接收node模块发来的状态反馈。 node node模块内嵌Canal,Canal监听数据库binlog中的变化传送给node的SETL模块。 原理描述 基于Canal开源产品，获取数据库增量日志数据。 典型管理系统架构，manager(web管理)+node(工作节点) a. manager运行时推送同步配置到node节点 b. node节点将同步状态反馈到manager上 基于zookeeper，解决分布式状态调度的，允许多node节点之间协同工作. 安装部署1.mysql 12345678910# 开启binloglog-bin=mysql-bin# 设置模式为ROWbinlog-format=ROW# 设置默认字符集init_connect='SET collation_connection = utf8_unicode_ci'init_connect='SET NAMES utf8'character-set-server=utf8collation-server=utf8_unicode_ciskip-character-set-client-handshake 1234567# 验证mysql&gt; show variables like '%binlog_format%';+---------------+-------+| Variable_name | Value |+---------------+-------+| binlog_format | ROW |+---------------+-------+ 2.安装aria2 1apt-get -y install aria2 123# 验证aria2c -varia2 version 1.19.0 3.安装启动zookeeper 12apt-get install zookeeper$&#123;zooKeeperHOME&#125;/bin ./zkServer.sh 4.打包otter 1234进入$otter_home目录执行：mvn clean install -Dmaven.test.skip -Denv=release发布包位置：$otter_home/target完成后有两个tar包：manager、node 5.manager解压修改配置启动 1234567891011121314151617181920212223242526272829303132333435363738394041# 配置## otter manager domain nameotter.domainName = 114.215.29.139## otter manager http portotter.port = 8289## jetty web config xmlotter.jetty = jetty.xml## otter manager database configotter.database.driver.class.name = com.mysql.jdbc.Driverotter.database.driver.url = jdbc:mysql://114.215.29.139:3406/otterotter.database.driver.username = roototter.database.driver.password = 123456## otter communication portotter.communication.manager.port = 8290## otter communication pool sizeotter.communication.pool.size = 10## default zookeeper addressotter.zookeeper.cluster.default = 114.215.29.139:2181## default zookeeper sesstion timeout = 60sotter.zookeeper.sessionTimeout = 60000## otter arbitrate connect manager configotter.manager.address = $&#123;otter.domainName&#125;:$&#123;otter.communication.manager.port&#125;## should run in product mode , true/falseotter.manager.productionMode = true## self-monitor enable or disableotter.manager.monitor.self.enable = true## self-montir interval , default 120sotter.manager.monitor.self.interval = 120## auto-recovery paused enable or disableotter.manager.monitor.recovery.paused = true# manager email user configotter.manager.monitor.email.host = smtp.gmail.comotter.manager.monitor.email.username =otter.manager.monitor.email.password =otter.manager.monitor.email.stmp.port = 465 12# 启动sh startup.sh 12345# 验证vi logs/manager.log2018-03-08 10:19:45.911 [] WARN com.alibaba.otter.manager.deployer.JettyEmbedServer - ##Jetty Embed Server is startup!2013-03-08 10:19:45.911 [] WARN com.alibaba.otter.manager.deployer.OtterManagerLauncher - ## the manager server is running now ...... 6.node解压修改配置启动 机器名称：可以随意定义，方便自己记忆即可 机器ip：对应node节点将要部署的机器ip，如果有多ip时，可选择其中一个ip进行暴露. (此ip是整个集群通讯的入口，实际情况千万别使用127.0.0.1，否则多个机器的node节点会无法识别) 机器端口：对应node节点将要部署时启动的数据通讯端口，建议值：2088 下载端口：对应node节点将要部署时启动的数据下载端口，建议值：9090 外部ip ：对应node节点将要部署的机器ip，存在的一个外部ip，允许通讯的时候走公网处理。 zookeeper集群：为提升通讯效率，不同机房的机器可选择就近的zookeeper集群. node这种设计，是为解决单机部署多实例而设计的，允许单机多node指定不同的端口 12# nid配置 (将环境准备中添加机器后获取到的序号，保存到conf目录下的nid文件，比如我添加的机器对应序号为1)echo 1 &gt; conf/nid 1234567891011121314# 配置## otter node dirotter.htdocs.dir = $&#123;otter.nodeHome&#125;/htdocsotter.download.dir = $&#123;otter.nodeHome&#125;/downloadotter.extend.dir= $&#123;otter.nodeHome&#125;/extend## default zookeeper sesstion timeout = 60sotter.zookeeper.sessionTimeout = 60000## otter communication pool sizeotter.communication.pool.size = 10## otter arbitrate &amp; node connect manager configotter.manager.address = 114.215.29.139:8290 12# 启动sh startup.sh 123# 验证vi logs/node/node.log2018-03-08 10:42:16.886 [main] INFO com.alibaba.otter.node.deployer.OtterLauncher - INFO ## the otter server is running now ...... 使用 添加数据库 a. 源库 jdbc:mysql://host:3306 b. 目标库 jdbc:mysql://host:3306 添加canal a. 提供数据库ip信息 添加同步表信息 a. 源数据表 test.example b. 目标数据表 test.example 添加channel 添加pipeline a. 选择node节点 b. 选择canal 添加同步映射规则 a. 定义源表和目标表的同步关系 启动 测试数据 manager说明及参数otter系统自带了manager，所以简化了一些admin管理上的操作成本，比如可以通过manager发布同步任务配置，接收同步任务反馈的状态信息等。 同步配置管理 添加数据源 canal解析配置 添加数据表 同步任务 同步状态查询 查询延迟 查询吞吐量 查询同步进度 查询报警&amp;异常日志 用户权限： ADMIN : 超级管理员 OPERATOR : 普通用户，管理某个同步任务下的同步配置，添加数据表，修改canal配置等 ANONYMOUS : 匿名用户，只能进行同步状态查询的操作. 具体配置参数channel参数 同步一致性. ==&gt; 基于数据库反查(根据binlog反查数据库)，基于当前变更(binlog数据)。针对数据库反查，在延迟比较大时比较有效，可将最新的版本快速同步到目标，但会对源库有压力. 同步模式. ==&gt; 行模式，列模式。行模式特点：如果目标库不存在记录时，执行插入。列模式主要是变更哪个字段，只会单独修改该字段，在双Ａ同步时，为减少数据冲突，建议选择列模式。 是否开启数据一致性. ==&gt; 请查看数据一致性文档：Otter数据一致性 a. 数据一致性算法 b. 一致性反查数据库延迟阀值 pipeline参数 并行度. ==&gt; 查看文档：Otter调度模型，主要是并行化调度参数.(滑动窗口大小) 数据反查线程数. ==&gt; 如果选择了同步一致性为反查数据库，在反查数据库时的并发线程数大小 数据载入线程数. ==&gt; 在目标库执行并行载入算法时并发线程数大小 文件载入线程数. ==&gt; 数据带文件同步时处理的并发线程数大小 主站点. ==&gt; 双Ａ同步中的主站点设置 消费批次大小. ==&gt; 获取canal数据的batchSize参数 获取批次超时时间. ==&gt; 获取canal数据的timeout参数 pipeline 高级设置 使用batch. ==&gt; 是否使用jdbc batch提升效率，部分分布式数据库系统不一定支持batch协议 跳过load异常. ==&gt; 比如同步时出现目标库主键冲突，开启该参数后，可跳过数据库执行异常 仲裁器调度模式. ==&gt; 查看文档：Otter调度模型 负载均衡算法. ==&gt; 查看文档：Otter调度模型 传输模式. ==&gt; 多个node节点之间的传输方式，RPC或HTTP. HTTP主要就是使用aria2c，如果测试环境不装aria2c，可强制选择为RPC 记录selector日志. ==&gt; 是否记录简单的canal抓取binlog的情况 记录selector详细日志. ==&gt; 是否记录canal抓取binlog的数据详细内容 记录load日志. ==&gt; 是否记录otter同步数据详细内容 dryRun模式. ==&gt; 只记录load日志，不执行真实同步到数据库的操作 支持ddl同步. ==&gt; 是否同步ddl语句 是否跳过ddl异常. ==&gt; 同步ddl出错时，是否自动跳过 文件重复同步对比 ==&gt; 数据带文件同步时，是否需要对比源和目标库的文件信息，如果文件无变化，则不同步，减少网络传输量. 文件传输加密 ==&gt; 基于HTTP协议传输时，对应文件数据是否需要做加密处理 启用公网同步 ==&gt; 每个node节点都会定义一个外部ip信息，如果启用公网同步，同步时数据传递会依赖外部ip. 跳过自由门数据 ==&gt; 自定义数据同步的内容 跳过反查无记录数据 ==&gt; 反查记录不存在时，是否需要进行忽略处理，不建议开启. 启用数据表类型转化 ==&gt; 源库和目标库的字段类型不匹配时，开启改功能，可自动进行字段类型转化 兼容字段新增同步 ==&gt; 同步过程中，源库新增了一个字段(必须无默认值)，而目标库还未增加，是否需要兼容处理 自定义同步标记 ==&gt; 级联同步中屏蔽同步的功能. Canal参数 connectionCharset ==&gt; 获取binlog时指定的编码 位点自定义设置 ==&gt; 格式：{“journalName”:””,”position”:0,”timestamp”:0};指定位置：{“journalName”:””,”position”:0};指定时间：{“timestamp”:0}; 内存存储batch获取模式 ==&gt; MEMSIZE/ITEMSIZE，前者为内存控制，后者为数量控制. 针对MEMSIZE模式的内存大小计算 = 记录数 * 记录单元大小内存存储buffer记录数内存存储buffer记录单元大小 心跳SQL配置 ==&gt; 可配置对应心跳SQL，如果配置 是否启用心跳HA，当心跳ＳＱＬ检测失败后，canal就会自动进行主备切换. Node参数 机器名称 ==&gt; 自定义名称，方便记忆 机器ip ==&gt; 机器外部可访问的ip，不能选择127.0.0.1 机器端口 ==&gt; 和manager/node之间RPC通讯的端口 下载端口 ==&gt; 和node之间HTTP通讯的端口 外部Ip ==&gt; node机器可以指定多IP，通过pipeline配置决定是否启用 zookeeper集群 ==&gt; 就近选择zookeeper集群 Zookeeper集群参数 集群名字 ==&gt; 自定义名称，方便记忆 zookeeper集群 ==&gt; zookeeper集群机器列表，逗号分隔，最后以分号结束 拓展数据合并 insert + insert -&gt; insert (数据迁移+数据增量场景) insert + update -&gt; insert (update字段合并到insert) insert + delete -&gt; delete update + insert -&gt; insert (数据迁移+数据增量场景) update + update -&gt; update update + delete -&gt; delete delete + insert -&gt; insert delete + update -&gt; update (数据迁移+数据增量场景) delete + delete -&gt; delete 数据入库算法入库算法采取了按pk hash并行载入+batch合并的优化 打散原始数据库事务，预处理数据，合并insert/update/delete数据(参见合并算法)，然后按照table + pk进行并行(相同table的数据，先执行delete,后执行insert/update，串行保证，解决唯一性约束数据变更问题)，相同table的sql会进行batch合并处理 提供table权重定义，根据权重定义不同支持”业务上类事务功能”，并行中同时有串行权重控制.业务类事务描述：比如用户的一次交易付款的流程，先产生一笔交易记录，然后修改订单状态为已付款. 用户对这事件的感知，是通过订单状态的已付款，然后进行查询交易记录。所以，可以对同步进行一次编排： 先同步完交易记录，再同步订单状态。 (给同步表定义权重，权重越高的表相对重要，放在后面同步，最后达到的效果可以保证业务事务可见性的功能，快的等慢的. ) 高可用仲裁器设计了三种异常机制指令： WARNING 只发送报警信息，不做任何S/E/T/L调度干预 ROLLBACK 尝试获取分布式锁，避免并发修改，其次修改分布式Permit为false，停止后续的所有S/E/T/L调度，然后删除所有当前process调度信息，通过zookeeper watcher通知所有相关node，清理对应process的上下文，pipe的数据存储会通过TTL来进行清理，不需要ROLLBACK干预。完成后，释放锁操作 RESTART 前面几个步骤和ROLLBACK基本类似，唯一不同点在于，在释放锁之前会尝试修改分布式Permit为true，重新开启同步，然后释放锁. 罗列了一下不同异常对应的处理机制 两个节点通讯时网络异常，节点发起ROLLBACK节点执行S/E/T/L模块，比如写数据库出现网络异常，节点发起ROLLBACK节点发生了CRASH，由manager进行监听，manager发现后发起RESTART 拓展性通过Otter Manager直接发布source文件代码，然后推送到node节点上即时生效，不需要重启任何java进程，有点动态语言的味道可以将class文件放置到extend目录或者打成jar包，放置在node启动classpath中，也可以通过Otter Manager指定类名的方式进行加载，这样允许业务完全自定义。(但有个缺点，如果使用了一些外部包加入到node classpath中，比如远程接口调用，目前EventProcessor的调用是串行处理，针对串行进行远程调用执行，效率会比较差.) EventProcessor接口示例： 123456789101112131415/** * 业务自定义处理过程 * * @author jianghang 2012-6-25 下午02:26:36 * @version 4.1.0 */public interface EventProcessor &#123;/** * 自定义处理单条EventData对象 * * @return &#123;@link EventData&#125; 返回值=null，需要忽略该条数据 */public EventData process(EventData eventData);&#125;","tags":[{"name":"数据库","slug":"数据库","permalink":"http://anning1994.github.io/tags/数据库/"},{"name":"实施细节","slug":"实施细节","permalink":"http://anning1994.github.io/tags/实施细节/"}]},{"title":"haproxy实现mysql集群负载均衡","date":"2017-10-22T12:51:05.000Z","path":"2017/10/22/haproxy实现mysql集群负载均衡/","text":"开始使用 Ubuntu 下载安装 1apt-get install haproxy 配置12345678910111213141516171819202122232425262728293031323334353637global log /dev/log local0 log /dev/log local1 notice chroot /var/lib/haproxy user haproxy group haproxy daemondefaults log global mode tcp option dontlognull contimeout 5000 clitimeout 50000 srvtimeout 50000 errorfile 400 /etc/haproxy/errors/400.http errorfile 403 /etc/haproxy/errors/403.http errorfile 408 /etc/haproxy/errors/408.http errorfile 500 /etc/haproxy/errors/500.http errorfile 502 /etc/haproxy/errors/502.http errorfile 503 /etc/haproxy/errors/503.http errorfile 504 /etc/haproxy/errors/504.httplisten status mode http bind *:11199 stats enable stats uri /admin stats auth admin:admin stats admin if TRUE stats realm Haproxy\\statisticsfrontend main bind 0.0.0.0:3506 default_backend mysqlbackend mysql balance leastconn server mysql1 114.215.29.139:3406 check server mysql2 114.215.29.139:3407 check linux启动1haproxy -f /etc/haproxy/haproxy.cfg 负载均衡算法 roundrobin，表示简单的轮询，每个服务器根据权重轮流使用，在服务器的处理时间平均分配的情况下这是最流畅和公平的算法。该算法是动态的，对于实例启动慢的服务器权重会在运行中调整。 static-rr，表示根据权重，建议关注；每个服务器根据权重轮流使用，类似roundrobin，但它是静态的，意味着运行时修改权限是无效的。另外，它对服务器的数量没有限制。 leastconn，表示最少连接者先处理，建议关注；leastconn建议用于长会话服务，例如LDAP、SQL、TSE等，而不适合短会话协议。如HTTP.该算法是动态的，对于实例启动慢的服务器权重会在运行中调整。 source，表示根据请求源IP，建议关注；对请求源IP地址进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。只要服务器正常，同一个客户端IP地址总是访问同一个服务器。如果哈希的结果随可用服务器数量而变化，那么客户端会定向到不同的服务器；该算法一般用于不能插入cookie的Tcp模式。它还可以用于广域网上为拒绝使用会话cookie的客户端提供最有效的粘连；该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 uri，表示根据请求的URI；表示根据请求的URI左端（问号之前）进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。只要服务器正常，同一个URI地址总是访问同一个服务器。一般用于代理缓存和反病毒代理，以最大限度的提高缓存的命中率。该算法只能用于HTTP后端；该算法一般用于后端是缓存服务器；该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 url_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name在HTTP GET请求的查询串中查找中指定的URL参数，基本上可以锁定使用特制的URL到特定的负载均衡器节点的要求；该算法一般用于将同一个用户的信息发送到同一个后端服务器；该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求；在每个HTTP请求中查找HTTP头，HTTP头将被看作在每个HTTP请求，并针对特定的节点；如果缺少头或者头没有任何值，则用roundrobin代替；该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。为每个进来的TCP请求查询并哈希RDP cookie；该机制用于退化的持久模式，可以使同一个用户或者同一个会话ID总是发送给同一台服务器。如果没有cookie，则使用roundrobin算法代替；该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 acl规则 ACL策略定义 如果请求的域名满足正则表达式返回true -i是忽略大小写acl denali_policy hdr_reg(host) -i ^(www.inbank.com|image.inbank.com)$ 如果请求域名满足www.inbank.com 返回 true -i是忽略大小写acl tm_policy hdr_dom(host) -i www.inbank.com 在请求url中包含sip_apiname=，则此控制策略返回true,否则为falseacl invalid_req url_sub -i sip_apiname=#定义一个名为invalid_req的策略 在请求url中存在timetask作为部分地址路径，则此控制策略返回true,否则返回falseacl timetask_req url_dir -i timetask 当请求的header中Content-length等于0时返回 trueacl missing_cl hdr_cnt(Content-length) eq 0 acl策略匹配相应 当请求中header中Content-length等于0 阻止请求返回403block if missing_cl block表示阻止请求，返回403错误，当前表示如果不满足策略invalid_req，或者满足策略timetask_req，则阻止请求。block if !invalid_req || timetask_req 当满足denali_policy的策略时使用denali_server的backenduse_backend denali_server if denali_policy 当满足tm_policy的策略时使用tm_server的backenduse_backend tm_server if tm_policy reqisetbe关键字定义，根据定义的关键字选择backendreqisetbe ^Host:\\ img dynamicreqisetbe ^[^\\ ]\\ /(img|css)/ dynamicreqisetbe ^[^\\ ]\\ /admin/stats stats 以上都不满足的时候使用默认mms_server的backenddefault_backend mms 连接池失效问题timeout client 300m 这个参数配置程序与haproxy的链接超时时间timeout server 300m 将这两个参数设置大","tags":[{"name":"数据库","slug":"数据库","permalink":"http://anning1994.github.io/tags/数据库/"},{"name":"实施细节","slug":"实施细节","permalink":"http://anning1994.github.io/tags/实施细节/"}]},{"title":"mysql主从复制","date":"2017-10-20T12:10:05.000Z","path":"2017/10/20/mysql主从复制/","text":"基本配置 Master库1.Master配置 修改my.cnf: 123456log-bin=mysql-bin #开启二进制文件server-id=2 #唯一标识binlog-ignore-db=information_schema #忽略数据库计入binlogbinlog-ignore-db=clusterbinlog-ignore-db=mysqlbinlog-do-db=ufind_db #开启数据库计入binlog 在Master数据库命令行中输入: 123456#为从库分配用户，包含文件权限 （5.6以下）&gt;GRANT FILE ON *.* TO '为从库分配的用户名'@'从库地址' IDENTIFIED BY '为从库分配的密码'; #为从库分配用户，包含复制二进制文件权限 （5.6及以上）&gt;GRANT REPLICATION SLAVE ON *.* TO '为从库分配的用户名'@'从库地址' IDENTIFIED BY '为从库分配的密码';#更新权限&gt;FLUSH PRIVILEGES 2.验证键入命令1mysql&gt; show master status; 显示以下信息则配置成功 123456+------------------+----------+--------------+----------------------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+----------------------------------+-------------------+| mysql-bin.000004 | 28125 | ufind_db | information_schema,cluster,mysql | |+------------------+----------+--------------+----------------------------------+-------------------+1 row in set (0.00 sec) 如果执行这个步骤始终为 Empty set(0.00 sec) ，那说明前面的my.cnf没配置对。 Slave库1.Slave配置修改my.cnf: 12345678910log-bin=mysql-binserver-id=3 #不可与主库重复binlog-ignore-db=information_schemabinlog-ignore-db=clusterbinlog-ignore-db=mysqlreplicate-do-db=ufind_db #同步数据库replicate-ignore-db=mysql #忽略同步的数据库log-slave-updates=1 #io线程同步数据时也计入logbin中slave-skip-errors=all #跳过错误slave-net-timeout=60 开启线程连接主库: 123mysql&gt; stop slave; #关闭Slavemysql&gt; change master to master_host='主库地址',master_port=主库的端口号,master_user='主库分配的用户',master_password='主库分配的密码',master_log_file='主库的File', master_log_pos=主库的Position;mysql&gt; start slave; #开启Slave 2.验证1mysql&gt; show slave status\\G; 在输出的信息中如果出现以下两条则说明主从配置成功Slave_IO_Running: YesSlave_SQL_Running: Yes 主从运维命令master端： 123show master status; #查看状态：show processlist; #查看slave下mysql进程信息reset master; #慎用，将清空日志及同步position slave端： 1234567891011show slave status;show slave logs;show processlist;reset slave; #慎用，将清空slave配置信息、日志及同步position在从服务器上跳过错误事件reset slave #清除日志同步位置标志，并重新生成master.infoshow slave hosts #主机运行，看连入的从机的情况。 手动同步（有数据时配置主从时使用） 先对主库锁表 FLUSH TABLES WITH READ LOCK; 备份数据 mysqldump -uroot -p -hlocalhost &gt; mysql.bak.sql 解锁主库 unlock tables; 查看主库的binlog文件和位置 show master status; 找出File和Position 使用scp命令把文件移动到从库 scp mysql.bak.sql root@192.168.128.101:/tmp/ 在从库上停止同步 mysql&gt; stop slave; 导入数据 mysql&gt; source /tmp/mysql.bak.sql 设置从库的同步开始文件和开始位置 change master to master_host = ‘主库主机’, master_user = ‘同步用户名’, master_port=3306, master_password=’’, master_log_file = ‘第3步中获取的file’, master_log_pos=第3步中获取的position; 从库上启动同步并检查 mysql&gt; start slave; mysql&gt; show slave status\\G 查看：","tags":[{"name":"数据库","slug":"数据库","permalink":"http://anning1994.github.io/tags/数据库/"},{"name":"实施细节","slug":"实施细节","permalink":"http://anning1994.github.io/tags/实施细节/"}]},{"title":"netty浅析","date":"2017-09-17T14:51:05.000Z","path":"2017/09/17/netty/","text":"为什么使用netty Netty是一个网络通信框架，其出现的原因主要是为了解决NIO的不足。如： NIO的类库和API繁杂，使用麻烦，你需要熟练掌握Selector、ServerSocketChannel、SocketChannel、ByteBuffer等； 需要具备其它的额外技能做铺垫，例如熟悉Java多线程编程，因为NIO编程涉及到Reactor模式，你必须对多线程和网路编程非常熟悉，才能编写出高质量的NIO程序； 可靠性能力补齐，工作量和难度都非常大。例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常码流的处理等等，NIO编程的特点是功能开发相对容易，但是可靠性能力补齐工作量和难度都非常大； NIO（Non-blocking I/O，在Java领域，也称为New I/O），是一种同步非阻塞的I/O模型，也是I/O多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高并发与大量连接、I/O处理问题的有效方式。 本文会从传统的阻塞I/O和线程池模型面临的问题讲起，然后对比几种常见I/O模型，一步步分析NIO怎么利用事件模型处理I/O，解决线程池瓶颈处理海量连接，包括利用面向事件的方式编写服务端/客户端程序。 传统BIO模型分析1234567891011121314151617181920212223&#123; ExecutorService executor = Excutors.newFixedThreadPollExecutor(100);//线程池 ServerSocket serverSocket = new ServerSocket(); serverSocket.bind(8088); while(!Thread.currentThread.isInturrupted())&#123;//主线程死循环等待新连接到来 Socket socket = serverSocket.accept(); executor.submit(new ConnectIOnHandler(socket));//为新的连接创建新的线程&#125;class ConnectIOnHandler extends Thread&#123; private Socket socket; public ConnectIOnHandler(Socket socket)&#123; this.socket = socket; &#125; public void run()&#123; while(!Thread.currentThread.isInturrupted()&amp;&amp;!socket.isClosed())&#123;死循环处理读写事件 String someThing = socket.read()//读取数据 if(someThing!=null)&#123; //处理数据 socket.write()//写数据 &#125; &#125; &#125;&#125; 上面的代码就是典型的传统BIO服务端监听代码，由于accept()、read()、write() 这三个方法是阻塞的、耗时的。如果是单线程的话，在执行阻塞代码是会使cpu空等，并且最重要的是，如果有10000个并发的话，那么等待时间是不能够接受的。 使用多线程的本质就是： 利用多核。 当I/O阻塞系统，但CPU空闲的时候，可以利用多线程使用CPU资源。 但是传统IO在使用多线程解决上面的问题时会严重依赖于线程，意味着每个请求都要建立一个线程，当客户端数量达到万级时，就需要建立万级的线程。线程占用的内存，切换线程资源昂贵，最终导致这种方案无法保证系统的伸缩性。 传统NIO模型分析所有的系统I/O都分为两个阶段：等待就绪和操作。举例来说，读函数，分为等待系统可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。 需要说明的是等待就绪的阻塞是不使用CPU的，是在“空等”；而真正的读写操作的阻塞是使用CPU的，真正在”干活”，而且这个过程非常快，属于memory copy，带宽通常在1GB/s级别以上，可以理解为基本不耗时。 12345678910111213141516171819202122232425262728interface ChannelHandler&#123; void channelReadable(Channel channel); void channelWritable(Channel channel); &#125; class Channel&#123; Socket socket; Event event;//读，写或者连接 &#125; //IO线程主循环: class IoThread extends Thread&#123; public void run()&#123; Channel channel; while(channel=Selector.select())&#123;//选择就绪的事件和对应的连接 if(channel.event==accept)&#123; registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器 &#125; if(channel.event==write)&#123; getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件 &#125; if(channel.event==read)&#123; getChannelHandler(channel).channelReadable(channel);//如果可以读，则执行读事件 &#125; &#125; &#125; Map&lt;Channel，ChannelHandler&gt; handlerMap;//所有channel的对应事件处理器 &#125; NIO由原来的阻塞读写（占用线程）变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。除了事件的轮询是阻塞的（没有可干的事情必须要阻塞），剩余的I/O操作都是纯CPU操作，没有必要开启多线程。","tags":[{"name":"java","slug":"java","permalink":"http://anning1994.github.io/tags/java/"},{"name":"IO","slug":"IO","permalink":"http://anning1994.github.io/tags/IO/"}]},{"title":"java基础3--HashMap","date":"2017-08-16T14:51:05.000Z","path":"2017/08/16/java基础3--HashMap/","text":"Map Map接口规定了一系列的操作，作为一个总规范它所定义的方法也是最基础，最通用的。 AbstractMapAbstractMap是HashMap、TreeMap，、ConcurrentHashMap 等类的父类。当我们宏观去理解Map时会发现，其实Map就是一个保存Entry&lt;K,V&gt;的数组，AbstractMap类的设计就是用代码来描述这句话。 AbstractMap的设计思路是将方法的实现都建立在操作Entry&lt;K,V&gt;数组上，从而将对Map所有方法的抽象转变为粒度更小的Entry&lt;K,V&gt;数组对象的抽象，从而不同的Map实现类只需要简单的继承AbstractMap，并且实现entrySet()方法去构造Entry&lt;K,V&gt;数组，便可以实现一个最简单的Map了。 12//AbstractMap中唯一的抽象方法public abstract Set&lt;Entry&lt;K,V&gt;&gt; entrySet(); 当通过实现entrySet()方法后，构造出自己的Entry集合后，其它常用操作便已经被AbstractMap去实现好了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//根据key获取valuepublic V get(Object key) &#123; Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); if (key==null) &#123; while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (e.getKey()==null) return e.getValue(); &#125; &#125; else &#123; while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (key.equals(e.getKey())) return e.getValue(); &#125; &#125; return null; &#125;//判断value是否存在 public boolean containsValue(Object value) &#123; Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); if (value==null) &#123; while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (e.getValue()==null) return true; &#125; &#125; else &#123; while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (value.equals(e.getValue())) return true; &#125; &#125; return false; &#125;//判断key是否存在 public boolean containsKey(Object key) &#123; Iterator&lt;Map.Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); if (key==null) &#123; while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (e.getKey()==null) return true; &#125; &#125; else &#123; while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (key.equals(e.getKey())) return true; &#125; &#125; return false; &#125; AbstractMap作为抽象类的意义就是为了使它将抽象的粒度缩小到最低，低到只对外提供一个抽象方法，而却将应用范围扩大，大到成为基本所有Map实现类的父类。 HashMap概述 HashMap是Map接口中最常用的一个实现类了，HashMap的主干部分是一个数组，每个数组中存放的都是一个链表，当链表超过一个设定的阈值时，又会转变为一个红黑树。 HashMap的这种数据结构是为了提高hash冲突多后的查找效率，我们如果只考虑功能，而不考虑性能、时间复杂度的情况下，去实现一个存放Key,Value的数据结构其实很容易，直接去定义一个Entry数组即可，这样我们就实现了Map的功能了，而查找的时间复杂度也很容易算出来是O(n)，显然这种时间复杂度作为一个优秀编程语言的底层集合容器是不能被接受的，而HashMpa则通过Hash函数直接将Key映射为Value的内存地址，从而在近似O(1)的时间内查询到数据的值。 HashMap中hash函数设计123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; hashMap在hash映射过程中，hashCode的值是一个32位的二进制数，约为40亿，要是直接使用，则需要分配tab的大小为40多亿，这显然是不合理的。 hashMap的容量都是2的n次方，默认值为16，这样的规则就是为了通过hashMap的容量-1去得出低位掩码，如16-1为0000000000000000000000000000001111，通过掩码与hashcode进行与操作，从而将hash值范围固定在hashMap的容量以内，使用(h = key.hashCode()) ^ (h &gt;&gt;&gt; 16)这步操作使key的高位低位都参与到运算，避免低位相同高位不同的hashCode产生碰撞。进过上面处理的hash值将能够尽可能的保证少的碰撞，并且能够将长度与tab的长度一致。","tags":[{"name":"java","slug":"java","permalink":"http://anning1994.github.io/tags/java/"},{"name":"基础知识","slug":"基础知识","permalink":"http://anning1994.github.io/tags/基础知识/"}]},{"title":"java基础2--对象的创建","date":"2017-04-24T13:39:14.000Z","path":"2017/04/24/java基础2--对象的创建/","text":"对象的创建详解 对象的创建java的对象是在运行时创建的，创建对象的的触发条件有以下几种： 用new语句创建对象，这是最常用的创建对象方法。 运用反射手段，调用java.lang.reflect.Constructor类的newInstance()实例方法。 调用对象的clone()方法。 运用反序列化手段，调用java.io.ObjectInputStream对象的readObject()方法。 对象创建过程java对象在创建时需要在方法区的运行时常量池去查找该类的符号引用，如果没有发现符号引用，说明该类还没有被JVM加载，所以要先进行JVM的加载。当JVM加载完时，会在java堆中分配内存。分配内存时会根据堆内存是否规整来分别进行两种方式的分配。 1.指针碰撞把内存分为可用的和已用的，在中间放置一个指针，如果要分配对象的空间，则把内存的指针向可用的一端移动当前需要分配对象大小的距离。 2.空闲列表当内存并不是很规整时，需要一个列表来维护那些地址是可用的，那些是不可用的。 当内存分配完成后需要对分配到内存空间的对象赋予零值（静态字段在类加载中就已经有值，所以不需要赋零值），接下来需要设置对象头的信息：如设置该对象的哈希码，属于哪个类，GC分代年龄等信息。从虚拟机的角度来看至此一个对象就创建完成，但是在java程序的角度看，对象的创建才刚刚开始，因为对象的值还没有设定，对象值得设定是由对象初始化来完成的，初始化就是调用构造方法过程。 对象的初始化当对象创建完成后，接下来就是进行对象的初始化了，也就是去执行构造方法。 父类的初始化当子类对象创建之前首先会调用父类的构造函数，也就是会初始化父类，但是父类并没有被创建，也就是并没有在堆中给父类分配新的存储空间，而只是对父类的变量进行了赋值。从而达到子类可以使用父类的属性和方法的目的。 静态类的初始化当一个类中有static修饰的方法或者是变量的话，那么当这个静态方法被第一次调用的时候，那么这个类就会初始化，就会调用此类的类构造器(在类加载过程中被JVM自动加入)，类构造器只初始化一次，触发条件为实例构造器执行，或者是静态任何一个静态成员被引用，也就是说这个类只会初始化一次。 普通类的初始化区别与父类和静态类的初始化，普通类的初始化是建立在对象创建之上的，也就是对象创建完成后会自动的去调用构造方法进行初始化。 对象创建及初始化实例看完上面文字上的简单说明总感觉少些什么东西？就像一碗牛肉拉面没有卤鸡蛋一样。所以笔者要通过一个java代码来将上面的知识点串起来，让你有一个更清晰的认识。 12345678910111213141516171819202122232425262728293031323334353637public class Parent &#123; int a = 1; static int b = 2; // 静态代码块 static &#123; System.out.println(\"执行Parent静态代码块：b =\" + b); b++; &#125; // 普通代码块 &#123; System.out.println(\"执行Parent普通代码块： a =\" + a); System.out.println(\"执行Parent普通代码块： b =\" + b); b++; a++; &#125; // 无参构造函数 Parent() &#123; System.out.println(\"执行Parent无参构造函数： a =\" + a); System.out.println(\"执行Parent无参构造函数： b =\" + b); &#125; // 有参构造函数 Parent(int a) &#123; System.out.println(\"执行Parent有参构造函数： a =\" + a); System.out.println(\"执行Parent有参构造函数： b =\" + b); &#125; // 方法 void fun() &#123; System.out.println(\"执行Parent的fun方法\"); &#125;&#125; 1234567891011121314151617181920212223242526272829public class Child extends Parent &#123; int c = 1; static int d = 2; // 静态代码块 static &#123; System.out.println(\"执行Child静态代码块：d =\" + d); d++; &#125; // 普通代码块 &#123; System.out.println(\"执行Child代码块： c =\" + c); System.out.println(\"执行Child代码块： d =\" + d); c++; d++; &#125; // 构造函数 Child() &#123; System.out.println(\"执行Child构造函数： c =\" + c); System.out.println(\"执行Child构造函数： d =\" + d); &#125; // 方法 void fun() &#123; System.out.println(\"执行Child的fun方法\"); &#125;&#125; 12345678910public class Test &#123; public static void main(String[] args) &#123; Child demo = new Child(); demo.fun(); System.out.println(\"…………………………………………………………………………………………………………………………\"); Child child = new Child(); child.fun(); &#125;&#125; 上面有三个很简单的类，一个Parent,一个Child,一个Test。当执行Test的main方法是会输出什么呢？ 12345678910111213141516171819202122//输出结果执行Parent静态代码块：b =2执行Child静态代码块：d =2执行Parent普通代码块： a =1执行Parent普通代码块： b =3执行Parent无参构造函数： a =2执行Parent无参构造函数： b =4执行Child代码块： c =1执行Child代码块： d =3执行Child构造函数： c =2执行Child构造函数： d =4执行Child的fun方法…………………………………………………………………………………………………………………………执行Parent普通代码块： a =1执行Parent普通代码块： b =4执行Parent无参构造函数： a =2执行Parent无参构造函数： b =5执行Child代码块： c =1执行Child代码块： d =4执行Child构造函数： c =2执行Child构造函数： d =5执行Child的fun方法 下面我们一起来看看这些输出是这么一步步产生的。 注：本文的重点不是虚拟机有关的详细执行，之后会专门写一个关于虚拟机加载的文章，所以有关细节问题都一笔带过了","tags":[{"name":"java","slug":"java","permalink":"http://anning1994.github.io/tags/java/"},{"name":"基础知识","slug":"基础知识","permalink":"http://anning1994.github.io/tags/基础知识/"}]},{"title":"java基础1--面向对象思想","date":"2017-04-16T08:34:32.000Z","path":"2017/04/16/java基础1--面向对象思想/","text":"解读面向对象 我们常见的编程范式有命令式编程，函数式编程，逻辑式编程，面向对象编程是一种命令式编程。 命令式编程是面向计算机硬件的一种抽象，有变量（存储单元），赋值语句（获取存储指令），表达式（引用存储单元和算术运算）和控制语句（跳转指令），命令式程序就是对一个冯诺依曼机的指令序列的抽象，面向对象是对我们现实世界模型的一个抽象，之后在映射到冯诺依曼机的指令序列。 面向对象的基本特性如果只是用变量，赋值语句，表达式，控制语句去构建现实世界模型的话会非常困难，所以面向对象的出现的根本原因就是就是为了解决这个问题。 面向对象让我们从指令代码操作变量转变为通过指令操作对象。 当我们理解了这个以后再去看面向对象的基本特征： 抽象封装 首先抽象就是建立一个对现实模型的抽象，封装就是将变量，赋值语句，表达式，控制语句进行组合来描述上面的抽象，并且将他们“打包”，看成一个原子结构，之后的程序逻辑都是围绕着这个原子结构进行的。 最后，面向对象的编程就是将原来的 ”模式一“ 改变为 ”模式二” 模式一：程序 = （赋值语句+表达式+控制语句）+ 变量 模式二：程序 = 对象 + 对象（对象之间的调用） 面向对象的高级特性对象之间的关联关系抽象，封装只是对现实模型和冯诺依曼机之间基本的映射关系，而现实世界中模型与模型之间还存在很多关系，如继承、组合、依赖等。 而维护这些关系也成为面向对象语言的一个特性，并且有相应的语法支持。 1.继承is-a组合：一个类继承具有相似功能的另一个类，根据需要在所继承的类基础上进行扩展。优点： 具有共同属性和方法的类可以将共享信息抽象到父类中，增强代码复用性，同时也是多态的基础。缺点： 子类中扩展的部分对父类不可见，另外如果共性比较少的时候使用继承会增加冗余代码。 2.组合has-a组合：has-a组合是在一个类中引用另一个类作为其成员变量。优点： 可扩展性和灵活性高。在对象组合关系中应优先考虑has-a组合关系。缺点： 具有共性的类之间看不到派生关系。 多态多态在代码复用中起着尤为重要的作用，如：对象A依赖对象B；对象C继承对象B；（说明对象C包含对象B，所以当对象C向上转型为对象B时不会出现信息的丢失，大部分静态编程语言都支持向上转型。）对象A引用对象B的操作也完全适用于对象C，依赖对象B和依赖C时有不同的表现，并且这个判断过程在运行期根据真实对象所决定的。 1234567891011121314151617181920212223242526272829303132public class A &#123; public void fun(B b)&#123; b.fun(); &#125;&#125;public class B &#123; public void fun()&#123; System.out.println(\"我是b\"); &#125;&#125;public class C extends B&#123; //重载 public void fun()&#123; System.out.println(\"我是c\"); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; A a = new A(); B b = new B(); C c = new C(); a.fun ( b ); a.fun ( c ); &#125;&#125;-------------------------------------------------Output:我是b我是c 以上是最简单的多态的例子，通过上面例子很难发现多态的好处，这样做的意义是什么？ 观察上面的代码会发现，A的fun( )方法参数为B，但是如果传递别的类型可不可以？答案是可以的，因为上面的代码中我们传递了B的子类C，如果有D、E、F….都继承B的话，也都可以传递到A的fun( )中，这样便起到了复用的作用。 但是还是体现不出来多态的好处，传递必须要继承这个类，不符合现实模型，比如A是播放叫声的装置，B是斑点狗，所以将B传递进去时会播放斑点狗的叫声，而C要是继承B,在现实生活世界模型中，C也是斑点狗才行。 那如果我想播放牧羊犬的叫声怎么办？用抽象类就可以。如果B是抽象类的话，抽象的是狗，所以C可以是任何狗，因为B中的所有东西都是抽象的，没有任何描述狗细节的东西，所以可以是任何狗。 最后还是发现不完善，那如果我要播放猫叫声怎么办？这时候会有个比抽象类还抽象的东西，那就是接口，一个超级有用的家伙，有了他就可以完全和现实世界模型对应起来了，因为接口抽象的是行为，所以当B为接口时，规定B有叫声方法，所以当A的fun方法中传递的B接口时，就可以理解为，只要传递实现叫声方法的就可以，无论什么。所以当猫实现这个接口后，就可以被放到声音播放器当中，同样马、猪、牛都可以，只要他们实现叫声接口就行，但是树可以吧？很显然是不可以的，因为现实世界中的树不可以叫，放到程序中即为树无法实现叫声接口，因为无法实现叫的方法。所以接口只抽象行为，完全可以实现现实模型的和面向对象的映射。 所以抽象程度从小到大分别为类&gt;抽象类&gt;接口。 当B为类时，A只能接收B子类。 当B为抽象类时，A能接收符合这个抽象的具体。 当B为接口时，A能接收实现B接口的任何东西，在当前上下文中就是有叫声的任何东西。 所以当B为普通类时，A就是一个 斑点狗叫声播放器。当B为抽象类时，A就为一个 狗的叫声播放器。而当B为接口时，A就是一个 叫声播放器，可以播放任何声音，这就是多态的意义。 一个斑点狗播放器和一个可以播放任何声音的播放器不存在那个更好，要根据实际的场景进行判断，一个作用域小一个作用域大。 其实在框架中或者“造轮子的人”用接口的比较多，而“用轮子的人”用普通类比较多，所以当阅读源码发现各种接口时不要疑惑，那多数是为了让代码更通用、作用域更大。","tags":[{"name":"java","slug":"java","permalink":"http://anning1994.github.io/tags/java/"},{"name":"基础知识","slug":"基础知识","permalink":"http://anning1994.github.io/tags/基础知识/"}]},{"title":"代码界的石器时代（转载）","date":"2017-03-17T09:20:00.000Z","path":"2017/03/17/代码界的石器时代/","text":"原文链接： https://github.com/justinyhuang/Functional-Programming-For-The-Rest-of-Us-Cn 公园漫步 时间机器启动……我们来到公元前380年，也就是2000多年前的雅典城外。这是一个阳光明媚的久违的春天，柏拉图和一个帅气的小男仆走在一片橄榄树荫下。他们正准备前往一个学院。天气很好，吃得很饱，渐渐的，两人的谈话转向了哲学。 “你看那两个学生，哪一个更高一些？”，柏拉图小心的选择用字，以便让这个问题更好的引导眼前的这个小男孩。小男仆望向水池旁边的两个男生，“他们差不多一样高。”。“差不多一样高是什么意思？”柏拉图问。“嗯……从这里看来他们是一样高的，但是如果走近一点我肯定能看出差别来。”柏拉图笑了。他知道这个小孩已经朝他引导的方向走了。“这么说来你的意思是世界上没有什么东西是完全相同的咯？”思考了一会，小男孩回答：“是的。万物之间都至少有一丁点差别，哪怕我们无法分辨出来。”说到点子上了！“那你说，如果世界上没有什么东西是完全相等的，你怎么理解完全相等这个概念？”小男仆看起来很困惑。“这我就不知道了。” 这是人类第一次试图了解数学的本质。柏拉图认为我们所在的世界中，万事万物都是完美模型的一个近似。他同时意识到虽然我们不能感受到完美的模型，但这丝毫不会阻止我们了解完美模型的概念。柏拉图进而得出结论：完美的数学模型只存在于另外一个世界，而因为某种原因我们却可以通过联系着这两个世界的一个纽带来认识这些模型。一个简单的例子就是完美的圆形。没有人见过这样的一个圆，但是我们知道怎样的圆是完美的圆，而且可以用公式把它描述出来。 如此说来，什么是数学呢？为什么可以用数学法则来描述我们的这个宇宙？我们所处的这个世界中万事万物都可以用数学来描述吗？数理哲学是一门很复杂的学科。它和其他多数哲学一样，更着重于提出问题而不是给出答案。数学就像拼图一样，很多结论都是这样推导出来的：先是确立一些互不冲突的基础原理，以及一些操作这些原理的规则，然后就可以把这些原理以及规则拼凑起来形成新的更加复杂的规则或是定理了。数学家把这种方法称为“形式系统”或是“演算”。如果你想做的话，可以用形式系统描述俄罗斯方块这个游戏。而事实上，俄罗斯方块这个游戏的实现，只要它正确运行，就是一个形式系统。只不过它以一种不常见的形式表现出来罢了。 如果半人马阿尔法上有文明存在的话，那里的生物可能无法解读我们的俄罗斯方块形式系统甚至是简单的圆形的形式系统，因为它们感知世界的唯一器官可能只有鼻子，也许它们是无法得知俄罗斯方块的形式系统了，但是它们很有可能知道圆形。它们的圆形我们可能没法解读，因为我们的鼻子没有它们那么灵敏，可是只要越过形式系统的表示方式（比如通过使用“超级鼻子”之类的工具来感知这些用味道表示的形式系统，然后使用标准的解码技术把它们翻译成人类能理解的语言），那么任何有足够智力的文明都可以理解这些形式系统的本质。有意思的是，哪怕宇宙中完全不存在任何文明，类似俄罗斯方块还有圆形这样的形式系统依旧是成立的：只不过没有智慧生物去发现它们而已。这个时候如果忽然一个文明诞生了，那么这些具有智慧的生物就很有可能发现各种各样的形式系统，并且用它们发现的系统去描述各种宇宙法则。不过它们可能不会发现俄罗斯方块这样的形式系统，因为在它们的世界里没有俄罗斯方块这种东西嘛。有很多像俄罗斯方块这样的形式系统是与客观世界无关的，比如说自然数，很难说所有的自然数都与客观世界有关，随便举一个超级大的数，这个数可能就和世界上任何事物无关，因为这个世界可能不是无穷大的。 历史回眸再次启动时间机……这次到达的是20世纪30年代，离今天近了很多。无论新旧大陆，经济大萧条都造成了巨大的破坏。社会各阶层几乎每一个家庭都深受其害。只有极其少数的几个地方能让人们免于遭受穷困之苦。几乎没有人能够幸运的在这些避难所里度过危机，注意，我说的是几乎没有，还真的有这么些幸运儿，比如说当时普林斯顿大学的数学家们。 新建成的哥特式办公楼给普林斯顿大学带来一种天堂般的安全感。来自世界各地的逻辑学者应邀来到普林斯顿，他们将组建一个新的学部。正当大部分美国人还在为找不到一片面包做晚餐而发愁的时候，在普林斯顿却是这样一番景象：高高的天花板和木雕包覆的墙，每天品茶论道，漫步丛林。 一个名叫阿隆佐·邱奇(Alonzo Church)的年轻数学家就过着这样优越的生活。阿隆佐本科毕业于普林斯顿后被留在研究院。他觉得这样的生活完全没有必要，于是他鲜少出现在那些数学茶会中也不喜欢到树林里散心。阿隆佐更喜欢独处：自己一个人的时候他的工作效率更高。尽管如此他还是和普林斯顿学者保持着联系，这些人当中有艾伦·图灵、约翰·冯·诺伊曼、库尔特·哥德尔。这四个人都对形式系统感兴趣。相对于现实世界，他们更关心如何解决抽象的数学问题。而他们的问题都有这么一个共同点：都在尝试解答关于计算的问题。诸如：如果有一台拥有无穷计算能力的超级机器，可以用来解决什么问题？它可以自动的解决这些问题吗？是不是还是有些问题解决不了，如果有的话，是为什么？如果这样的机器采用不同的设计，它们的计算能力相同吗？在与这些人的合作下，阿隆佐设计了一个名为lambda演算的形式系统。这个系统实质上是为其中一个超级机器设计的编程语言。在这种语言里面，函数的参数是函数，返回值也是函数。这种函数用希腊字母lambda（λ），这种系统因此得名4。有了这种形式系统，阿隆佐终于可以分析前面的那些问题并且能够给出答案了。除了阿隆佐·邱奇，艾伦·图灵也在进行类似的研究。他设计了一种完全不同的系统（后来被称为图灵机），并用这种系统得出了和阿隆佐相似的答案。到了后来人们证明了图灵机和lambda演算的能力是一样的。 如果二战没有发生，这个故事到这里就应该结束了，我的这篇小文没什么好说的了，你们也可以去看看有什么其他好看的文章。可是二战还是爆发了，整个世界陷于火海之中。那时的美军空前的大量使用炮兵。为了提高轰炸的精度，军方聘请了大批数学家夜以继日的求解各种差分方程用于计算各种火炮发射数据表。后来他们发现单纯手工计算这些方程太耗时了，为了解决这个问题，各种各样的计算设备应运而生。IBM制造的Mark一号就是用来计算这些发射数据表的第一台机器。Mark一号重5吨，由75万个零部件构成，每一秒可以完成3次运算。战后，人们为提高计算能力而做出的努力并没有停止。1949年第一台电子离散变量自动计算机诞生并取得了巨大的成功。它是冯·诺伊曼设计架构的第一个实例，也是一台现实世界中实现的图灵机。相比他的这些同事，那个时候阿隆佐的运气就没那么好了。到了50年代末，一个叫John McCarthy的MIT教授（他也是普林斯顿的硕士）对阿隆佐的成果产生了兴趣。1958年他发明了一种列表处理语言（Lisp），这种语言是一种阿隆佐lambda演算在现实世界的实现，而且它能在冯·诺伊曼计算机上运行！很多计算机科学家都认识到了Lisp强大的能力。1973年在MIT人工智能实验室的一些程序员研发出一种机器，并把它叫做Lisp机。于是阿隆佐的lambda演算也有自己的硬件实现了！","tags":[{"name":"宏观知识","slug":"宏观知识","permalink":"http://anning1994.github.io/tags/宏观知识/"}]},{"title":"关于写博客的一点小想法","date":"2017-03-15T14:04:04.000Z","path":"2017/03/15/关于写博客的一点小想法/","text":"千里之行，始于足下越来越发现，一件复杂的事情只要满足两个条件就可以做好，一是坚持不懈、二是有个开始。 很早以前就有写博客的想法，直到现在才正式动笔，中间很长一段时间都是在想这件事是如何的复杂，如何困难。直到意识到工作中遇到的很难的事，也都通过一点一点的努力完成了。回头想想，自己之前认为困难的事，其实难都难在不去开始。这些新的思想觉悟便是自己搭建这个博客的主要驱动力。 思所以危则安矣避免技术更新导致自我价值降低很重要。 软件研发技术迭代很快，是一个 表面 上没有技术积累的行业。所以思维方式，学习方法，核心概念的理解，远远比那些机械的记忆程序的配置，单纯的参考网上的例子实现功能要重要的多。如果仅仅是代码的搬运工，极可能被技术更新的大浪所埋没。所以，透彻的理解技术映射出的本质，拥有这样的思想是每一个“优质码农”都应该具备的，看过很多阿里的技术沙龙，每一个主讲人的特点都是去解释思想，本质。而那些技术的用法都是一概而过。抛开技术而言，这些人在分享过程中也是很有特点的： 条理清晰 思维缜密 谦逊客观技术横纵双向发展善于分析新旧技术的核心区别 这些天赋异禀的人的特点，看起来就像”成功的**所必备的n个**”的俗鸡汤，但是这些特点确实是很值得去借鉴和培养的。 厚积而薄发其实自己搭建博客主要是因为可以装逼自主方便，其目的是整理一些印象笔记里平时记录的东西。 一方面秉承互联网大环境分享精神的大统，另一方面可以在写的过程中可以系统的完善自己的知识体系。在学习新知识的同时也要时不时的回头去沉淀一下自己的旧知识。 我相信收获一定会有的，一直往前走，它会突然出现在未来的某一天，共勉。","tags":[{"name":"随笔","slug":"随笔","permalink":"http://anning1994.github.io/tags/随笔/"}]}]